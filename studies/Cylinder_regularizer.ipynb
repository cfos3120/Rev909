{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fda8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyvista as pv\n",
    "pv.set_jupyter_backend('static')\n",
    "import plotly.graph_objects as go\n",
    "import sys\n",
    "sys.path.insert(0, r'C:\\Users\\Noahc\\Documents\\USYD\\PHD\\8 - Github\\Rev909')\n",
    "from utils.mesh_utils import BatchedAngularMeshRavel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd50364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 21004, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = r'C:\\Users\\Noahc\\Documents\\USYD\\PHD\\0 - Work Space\\Markov Studies v2\\RAS_Re100k.npy'\n",
    "mesh_path = r\"C:\\Users\\Noahc\\Documents\\USYD\\tutorial\\cylinder_mno_turb5\\case.foam\"\n",
    "\n",
    "coord_points = np.load(dataset_path[:-4]+'_coords.npy')\n",
    "dataset = np.load(dataset_path)\n",
    "Ravler = BatchedAngularMeshRavel(coord_points,m=59,n=356)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0bbe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Dataset has shape: torch.Size([901, 59, 356, 2]) with shape 59x356\n",
      "Dataset is split for training (90%) to 810 - 91 with downsample of 1x\n",
      "21.97066\n",
      "146.39618\n"
     ]
    }
   ],
   "source": [
    "data = Ravler.to(torch.tensor(dataset[...,:2], dtype=torch.float32), forward=True)\n",
    "T, W, H, C = data.shape\n",
    "\n",
    "T_in = 0\n",
    "split = 0.9\n",
    "sub = 1\n",
    "\n",
    "T = T - T_in\n",
    "print(f'Raw Dataset has shape:', data.shape, f'with shape {W:n}x{H:n}')\n",
    "ntrain = int(split*T)\n",
    "ntest = T - ntrain\n",
    "print(f'Dataset is split for training ({100*split:.0f}%) to {ntrain:n} - {ntest:n} with downsample of {sub:n}x')\n",
    "\n",
    "W = int(W/sub) \n",
    "H = int(H/sub) \n",
    "data = data[T_in:, ::sub, ::sub, :]\n",
    "\n",
    "max_norm = np.linalg.norm(data[:,T_in:,...], axis=(2, 3)).max()\n",
    "print(max_norm)\n",
    "max_norm = np.linalg.norm(data[T_in:,...], axis=(1, 2)).max()\n",
    "print(max_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7c8c30b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146.39618  34.69926]\n"
     ]
    }
   ],
   "source": [
    "max_norm = np.linalg.norm(data[...,:], axis=(1, 2)).max(axis=0)#.max(axis=0)\n",
    "print(max_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ac78ba94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(isinstance(x, np.ndarray) for x in [max_norm, max_norm*4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f09d8ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance([max_norm, max_norm*4], (list, tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "73486817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([146.39618,  34.69926], dtype=float32),\n",
       " array([585.5847 , 138.79704], dtype=float32)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[max_norm, max_norm*4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "82fd2c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([146.39618,  34.69926], dtype=float32),\n",
       " array([585.5847 , 138.79704], dtype=float32)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[max_norm, max_norm*4]#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7a2c712d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 21004, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5620c7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.39621\n"
     ]
    }
   ],
   "source": [
    "max_norm = np.linalg.norm(dataset[T_in:,...,:2], axis=(1)).max()\n",
    "print(max_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1094b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dissipative_utils import sample_uniform_spherical_shell, linear_scale_dissipative_target\n",
    "class RegulatorSampler():\n",
    "    def __init__(self, \n",
    "                 radii, \n",
    "                 shape, \n",
    "                 scale_down_factor = 0.5, \n",
    "                 weight = 0.01, \n",
    "                 sampling_fn = sample_uniform_spherical_shell,\n",
    "                 target_fn = linear_scale_dissipative_target,\n",
    "                 loss_fn=torch.nn.MSELoss(reduction='mean')):\n",
    "        \n",
    "        self.sampling_fn = sampling_fn\n",
    "        self.target_fn = target_fn\n",
    "        self.loss_function = loss_fn\n",
    "        self.weight = weight\n",
    "        self.scale_down_factor = scale_down_factor\n",
    "        \n",
    "        if all(isinstance(x, np.ndarray) for x in radii):\n",
    "            assert len(radii[0]) == shape[-1]\n",
    "            print('Regularizer enforces per channel')\n",
    "            self.split_channels = True \n",
    "            radii = np.concatenate([max_norm[None,...], max_norm[None,...]*4], axis = 0)\n",
    "        else:\n",
    "            self.split_channels = False \n",
    "\n",
    "        # get shape((S, S, 1))\n",
    "        self.shape = shape\n",
    "        # get radii\n",
    "        self.radii = radii\n",
    "\n",
    "    def get_input(self, batch_s):\n",
    "        if self.split_channels:\n",
    "            input_sample = []\n",
    "            for i in range(self.shape[-1]):\n",
    "                input_sample.append(torch.tensor(self.sampling_fn(batch_s, self.radii[...,i], self.shape[:-1]+ (1,)), dtype=torch.float))\n",
    "            input_sample = torch.concatenate(input_sample, dim=-1)\n",
    "        else:\n",
    "            input_sample = torch.tensor(self.sampling_fn(batch_s, self.radii, self.shape), dtype=torch.float)\n",
    "        return input_sample\n",
    "    \n",
    "    def get_target(self, x_diss):\n",
    "        return self.target_fn(x_diss, self.scale_down_factor)\n",
    "    \n",
    "    def loss_fn(self, out, y):\n",
    "        return self.weight * self.loss_function(out, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66e369b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146.39618,  34.69926], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3e9623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 59, 356, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_uniform_spherical_shell(4,[max_norm, max_norm*4],(W, H, 2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e97b804d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([146.39618,  34.69926], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8862d48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([146.39618,  34.69926], dtype=float32), array([585.5847 , 138.79704], dtype=float32)]\n",
      "[[146.39618  34.69926]\n",
      " [585.5847  138.79704]]\n",
      "[146.39618 585.5847 ]\n"
     ]
    }
   ],
   "source": [
    "max_norm_2 = np.concatenate([max_norm[None,...], max_norm[None,...]*4], axis = 0)\n",
    "print([max_norm, max_norm*4])\n",
    "print(max_norm_2)\n",
    "print(max_norm_2[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f79ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:4, ..., :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c97d4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_class = RegulatorSampler(radii=[max_norm, max_norm*4], shape=(W, H, 2), scale_down_factor=0.5, weight=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3ba77a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 59, 356, 2])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_diss = sampling_class.get_input(x.shape[0])\n",
    "x_diss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7a962f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([341.09988, 342.80563], dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(x_diss, axis=(1, 2)).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ea903386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([170.54994, 171.40282], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(y_diss, axis=(1, 2)).max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f0e0e4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_diss = sampling_class.get_input(x.shape[0])\n",
    "assert(x_diss.shape == x.shape)\n",
    "y_diss = sampling_class.get_target(x_diss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
